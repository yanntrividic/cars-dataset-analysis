---
title: "Cars dataset analysis"
author:
- Aissatou Signate
- Jacky Thay
- Yann Trividic
output:
  html_document:
    df_print: paged
  pdf_document: default
abstract: |
  This is the abstract.
  It consists of two paragraphs
tags:
- data analysis
- cars
- dataset
- R
- notebook
- pca
- clustering
- statistics
editor_options: 
  markdown: 
    wrap: sentence
---

# Sujet

## Sujet du projet

Ce projet est un travail sur données réelles.
Il s'agit de mettre en oeuvre une ou plusieurs méthodes vues en cours sur un jeu de données proposé pour chaque groupe.

Le projet doit suivre les étapes suivantes :

-   analyser le jeu de données proposé afin de choisir l'approche la plus adaptée à votre problème,
-   effectuer un prétraitement de votre base de données (si nécessaire),
-   justifier le choix de votre approche,
-   tester l'approche choisie sur l'ensemble de données en utilisant les options vues en cours,
-   analyser et commenter les résultats obtenus.

## Présentation du rapport

Le rapport du projet doit présenter de façon claire et concise:

-   l'objet de l'analyse,
-   la description des données (individus/variables utilisées, variables supplémentaires etc.),
-   l'analyse proprement dite,
-   les commentaires sur les résultats obtenus.

Ce rapport ne devrait pas dépasser 10 pages (les codes sources des programmes utilisés peuvent être mis en annexe).

Le projet sera jugé selon les critères suivants:

-   adéquation des méthodes utilisées aux données et problème étudiés,
-   richesse des analyses proposées (au delà du minimum requis),
-   justesse des commentaires sur les résultats,
-   qualité de la présentation du rapport.

## Remise du projet

Vous devez déposer votre rapport en format .pdf portant le nom : nom1_nom2_nom3_trinomeX.pdf au plus tard le 20 mai 2021 sous Moodle dans le dossier Rendu_projet_TND.

# Notes sur les différentes étapes

**1. analyser le jeu de données proposé afin de choisir l'approche la plus adaptée à votre problème**

-   Pour la **description des données**, tout ce qu'on a besoin de savoir est là : <https://www.kaggle.com/yugagrawal95/k-means-clustering-using-seaborn-visualization>. Décrire les différentes colonnes du jeu de données, les valeurs pouvant être prises par celles-ci, leur mode (numérique [entier, double, continue, discret], caractère, logique, `NULL`...), etc. Le nombre de colonnes aussi et la syntaxe comptent aussi. Quelles sont les données ordinales/qualitatives et quelles sont les données quantitatives.
-   Il faut **poser une problématique**, aussi générale soit-elle. Par exemple, quelle est l'influence des diverses variables sur les performances d'une voiture ? Comprendre quelles sont les avantages et les inconvénients d'avoir plus de chevaux, une plus grosse consommation d'essence, etc.
-   Combien a-t-on d'individus, combien de variables ?

**2. effectuer un prétraitement de votre base de données (si nécessaire)**

-   Effectuer une **analyse descriptive de base** (regarder ce qu'il est possible de déduire de la fonction `summary`, en faire un résumé, regarder ce qui ressort de la fonction `pairs`, et la fonction `quantile`, peut-être la matrice de corrélations ?)
-   Il y a-t-il des données ordinales ? [Non.] Textuelles ? [Oui, mais non, c'est pas des textes] Qualitatives ? [Oui.] Nominales ? [Oui.] Comment est-ce qu'on pourrait les traiter le mieux possible ? Les utiliser comme marqueurs dans la PCA et la CAH ? Par défaut, on mettra les variables qualitatives en tant que variables supplémentaires (ni l'ACP ni la CAH ne peuvent les traiter). Certaines variables quantitatives peuvent être considérées comme supplémentaires (par exemple, les variables qui décrivent d'autres variables ; le pH et le taux d'acide citrique)
-   Lister les variables qui sont le plus corrélées. On devrait retrouver ces corrélations dans les résultats de l'ACP
-   Potentiellement centrer les valeurs si les résultats de l'analyse univariée donne des résultats très hétérogènes. Càd si les valeurs prises par les variables sont sur des intervalles/variances/moyennes très différents.
-   Est-ce que tous les objets sont complets ? Il y a-t-il des **valeurs manquantes** (fonction `is.na`) ? Il y a-t-il des **valeurs aberrantes** à enlever (justifier pourquoi on les enlève) ? Décide-t-on de tolérer une marge d'erreur, remplacer les valeurs, supprimer les individus ? Essayer de comprendre pourquoi ces valeurs sont là, proposer des hypothèses si pertinent. Avec k-means par exemple, les valeurs aberrantes peuvent donner des résultats erronés. La forme des clusters est aussi importante.

**3. justifier le choix de votre approche**

-   Choisir un ensemble d'algorithmes à utiliser parmi ceux qu'on a vu (k-means, PCA, CAH, HCPC) et expliquer en quoi il serait pertinent de les utiliser au vu de ce qu'on a déduit du point précédent.
    Pour déterminer quel algo choisir, se référer aux caractéristiques des méthodes de classification (voir cours).

    -   Pourquoi l'ACP ? Trouver des individus similaires ; comment est-ce qu'une caractéristique va affecter les valeurs des autres caractéristiques, etc.

-   Avec chacun des algorithmes utilisés, justifier le choix la valeur de chacun des paramètres (exemple : pourquoi utiliser la méthode de Ward (voir cours), quels sont les résultats avec les autres méthodes ?
    Quel critère de qualité ?)

-   Ajouter l'utilisation d'autres d'outils statistiques : regression, chi², degré d'asymétrie (skewness), degré d'aplatissement (Kurtosis)...

**4. tester l'approche choisie sur l'ensemble de données en utilisant les options vues en cours**

-   Idéalement, je pense qu'il serait bien d'**enregistrer un fichier** `results.csv`, contenant les données de bases et une colonne pour chaque résultat pertinent.
-   Dans certains cas, il pourrait être intéressant de **diviser le jeu de données en différents sous-jeux** (par exemple, les voitures d'une certaine décennie, ou les voitures avec un certain type de moteur) et regarder comment les résultats varient au sein de ces sous-jeux. Pour ça, utiliser la fonction `aggregate`.
-   Consolider les résultats (consolider les résultats de la PCA avec HCPC, les résultats de la CAH avec k-means, etc.).

**5. analyser et commenter les résultats obtenus**

-   Se baser sur les corrections fournies pour les TD 5 et 6.
-   **Caractérisation des classes :** la partition obtenue peut être considérée comme une variable quantitative, chercher une variable qui caractérise le mieux une partition revient à chercher les variables qui caractérisent le mieux cette variable qualitative. Pour chaque variable quantitative, on va construire un modèle d'analyse de variance entre la variable quantitative, qui aura de le rôle de la variable réponse, en fonction de la variable de classe (qualitative). On construit ensuite un test de Fisher pour voir s'il y a un effet de la variable de classe sur la variable quantitative. On peut concerver les variables ayant une probabilité critique inférieure à 5 %, et trier ces variables par probabilité croissante. Attention : les variables ayant eu un rôle actif dans la construction des résultats (par exemple lorsqu'elles participent au calcul de la distance) ne sont pas totalement indépendantes des classes attribuées. Seules les probabilités critiques associées aux variables supplémentaires (dans notre cas, `brand`) peuvent être réellement interprétées comme décrit ici. Le test de Fisher nous permettrait donc de vérifier nos résultats de manière quantifiée et de savoir si les classes obtenues seraient représentatives ou non des classes obtenues avec les différents algorithmes de partitionnement.
-   On pourrait potentiellement colorer les résultats de l'ACP en fonction de certaines variables ayant beaucoup contribué dans les axes principaux.
-   Calculer quel est le nombre d'axe optimal à garder grâce au pourcentage d'inertie de l'ACP. Pareil pour la CAH.
-   Pour l'ACP, vérifier la qualité de la projection des différentes variables en regardant le cos² associé à cette variable.
-   Dans certains cas, un axe de l'ACP peut avoir été défini par un seul individu, ou une seule variable. Il peut être intéressant de refaire une ACP sans cette variable/individu si l'interprétation de ce phénomène le justifie.
-   Pour chaque interprétation, il est important de revenir aux données de départ pour les valider et citer des exemples.\

**2. Objet de l'analyse**

-   Expliciter des tendances sous-jacentes du jeu de données, analyse descriptive du jeu de données pour mieux comprendre les liens entre les différentes variables, et ainsi mieux comprendre les performances des véhicules en fonction de leurs attributs.

# Code

## 1. Lecture des données

Les données sont contenues dans un fichier `TXT`, les colonnes sont séparées par le caractère `,` et les lignes par un retour à la ligne.
Les valeurs décimales sont séparées des valeurs entières par le caractère `.`.

```{r read_file}
cars = read.table("../data/275-cars.txt", sep=",", header=T)
head(cars)
```

## 2. Descriptions du jeu de données

```{r dataset_dimensions}
dim(cars)
```

Le jeu de données cars contient 261 individus définis par 8 variables.
Chaque individu représente une liste de caractéristiques d'une voiture.
En se basant sur [ce lien](https://www.kaggle.com/abineshkumark/carsdata), on obtient les descriptions suivantes :

1.  `mpg` [numérique, réel, continu] : la quantité prédite de gallons par mille (continue, arrondie à l'unité)
2.  `cylinders` [numérique, entier, discret] : le nombre de cylindres dans le moteur. Peut être 3, 4, 6 ou 8.
3.  `cubicinches` [numérique, entier, continu] : mesure du volume du moteur de la voiture en pouces cube.
4.  `hp` [numérique, entier, continu] : puissance réelle du moteur en chevaux.
5.  `weightlbs` [numérique, entier, continu] : le poids de la voiture en livres.
6.  `time.to.60` [numérique, entier, continu] : durée nécessaire pour aller de 0 à 60 milles par heure.
7.  `year` [numérique, entier, discret] : année de fabrication de la voiture.
8.  `brand` [textuel, qualitatif, catégorielle] : région géographique de la marque de la voiture.

## 3. Prétraitement

```{r na_values}
cars[rowSums(is.na(cars)) > 0,] # counts the number of rows with NA values 
```

```{r}
#le = LabelEncoder().fit(cars['brand']) # TODO: à quoi ça sert ça ?
```

Le jeu de données ne contient aucune valeur manquante, il peut donc être utilisé tel quel pour la suite de l'analyse.

Pour l'instant, seule la variable `brand` peut être considérée comme une variable supplémentaire car celle-ci est une variable textuelle et catégorielle.
Nous pouvons par ailleurs la considérer comme de type `factor`.

Au premier abord, toutes les autres variables doivent être utilisés dans l'analyse, celles-ci ne semblant pas être liées entre elles directement.
On peut noter que les unités de mesure associées aux différentes variables sont toutes différentes ; le jeu de données sera analysé en prenant en compte ces caractéristiques.

```{r normalisation}
cars$brand = as.factor(cars$brand) # Transformation en factor
cars.scaled = as.data.frame(cbind(scale(cars[-8]), cars$brand)) # On garde les données textuelles tel quel
```

## 4. Analyse univariée

### 4.1 Sommaire, distributions et critères de position

#### 4.1.1 Variables quantitatives

Grâce à la fonction `summary`, nous avons un aperçu global des différentes distributions des variables composant notre base de données en calculant des statistiques de base (critères de position et critères de dispersion).
Pour les variables quantitatives, `summary` nous retourne le minimum, le maximum, la moyenne et les trois quartiles.

```{r summary}
summary(cars[-8]) # the last column is not included as it is a textual variable
```

Pour calculer des quantiles d'un jeu d'observations stocké dans un vecteur $v$, nous utilisons la fonction `quantile`.
Sans plus d'argument, celle-ci calcule les quantiles à 0 %, 25 %, 50 %, 75 % et 100 %.
Pour avoir les quantiles à d'autres ordres, il faut manipuler le paramètre `probs`.
Dans notre cas , nous les calculons par intervalle de 10 % :

```{r quantiles}
apply(cars[1:7], MARGIN=2, FUN=quantile, probs=seq(0, 1, 0.1))
```

Un box-plot est un graphique composé d'un rectangle, deux droites sortent afin de représenter certains éléments des données.

La valeur centrale du graphique est la médiane (il existe autant de valeur supérieures qu'inférieures à cette valeur dans l'échantillon).

Les bords du rectangle sont les quartiles (Pour le bord inférieur, un quart des observations ont des valeurs plus petites et trois quart ont des valeurs plus grandes, le bord supérieur suit le même raisonnement).

Les extrémités des moustaches sont calculées en utilisant 1.5 fois l'espace interquartile (la distance entre le 1er et le 3ème quartile).
On peut remarquer que 50% des observations se trouvent à l'intérieur de la boîte.
**[Yann : je suis pas sûr qu'il soit utile d'expliquer comment lire un boxplot, pour moi les quatre phrases qui précèdent ne sont pas utiles. A la limite, on pourrait mettre un lien vers la page Wiki si vraiment ça semble nécessaire]**

```{r boxplots}
par(mar=c(7,3,2,2))
boxplot(cars.scaled[-8], las=2, main="Diagrammes en boîte des variables quantitatives de cars")
```

**[Yann : aussi, j'pense que ce serait mieux si on avait en général les interprétations des graphiques après que les graphiques aient été affichés, du coup j'ai déplacé les graphiques]**

Ces diagrammes en boîtes permettent de visualiser plus facilement les résultats obtenus précédemment grâce à la fonction `summary`.
Par exemple, pour la variable `mpg`, on peut lire que sa valeur médiane est $22$, et que les valeurs sont un peu plus dispersées au-dessus de cette valeur médiane.
Pour la variable `cylinders`, on remarque une symétrie parfaite : la distribution en-dessous de la médiane est très similaire à celle au-dessus de celle-ci.
Son coefficient d'asymétrie est proche de $0$.
La même observation peut être faite concernant la variable `year`.

En ce qui concerne la variable `time.to.60`, on peut noter la présence de valeurs aberrantes.
Une valeur aberrante est une valeur qui s'écarte fortement des valeurs des autres observations, anormalement faible ou élevée.
Ici, ces valeurs correspondent à des voitures ayant une accélération anormalement élevée (\~8 secondes pour atteindre 60 mph pour la plus rapide) ou anormalement faible (\~25 secondes pour la plus lente).
Ces valeurs ne semblent pas être des erreurs de mesure mais simplement des voitures sortant de la norme.
Dans certains cas, il est nécessaire d'effectuer un traitement particulier sur ces valeurs.
Avec ces valeurs en particuliers, nous considérons qu'il est possible de continuer l'analyse en l'état, celles-ci n'allant pas poser pas de problèmes.

#### 4.1.2 Variables qualitatives

Le jeu de données `cars` contient, en plus des sept variables quantitatives déjà abordées, une variable qualitative : la variable `brand`.
Cette donnée, par sa nature, doit être traitée séparément du reste.

```{r piechart-brand}
library(ggplot2)
library(dplyr)

contingency_table <- table(cars$brand) 
df <- data.frame(brand = names(contingency_table),
                 Distribution = as.vector(contingency_table))

ggplot(df, aes(x = "", y = Distribution, fill = brand)) +
    geom_bar(width = 1, stat = "identity", color = "white") +
    coord_polar("y", start = 0)
```

Comme on peut le voir, la distribution des individus en fonction de la variable brand est tout sauf uniforme : près de deux tiers sont des voitures américaines tandis que les voitures japonaises et européennes se partagent de manière à peu près égale le dernier tiers des données.
Cette surréprésentation des voitures américaines sera à prendre en compte tout au long de l'analyse.

```{r table-contingence-brand}
# TODO: Ajouter la table de contingence en fonction de brand et interpréter les résultats
```

### 4.2 Corrélations

Une matrice de corrélation est utilisée pour visualiser la liaison linéaire entre plusieurs variables.
Il s'agit d'un tableau contenant les coefficients de corrélation entre chaque variable.
Pour l'obtenir, on peut utiliser la fonction `cor`, présente dans les fonctions de base de R.

```{r matrice  correlations}
cars.correlations <- cor(cars[-8]) # the last column is not included as it is a textual variable
#write.csv(cars.correlations, file="../data/correlations.csv")
cars.correlations
```

Nous pouvons également visualiser et représenter graphiquement notre matrice avec un corrélogramme.
Cet outil permet de mettre en évidence les variables les plus corrélées : les coefficients de corrélation sont colorés en fonction de leur valeur.

La valeur $1$ indique que les deux variables sont exactement corrélées, c'est le cas avec une relation parfaitement linéaire entre deux variables.
À l'inverse, une corrélation de $-1$ entre deux variables indique une parfaite anti-corrélation entre ces dernières.
Les corrélations dont la valeur absolue sont supérieures à $0,5$ peuvent être considérées comme des corrélations fortes.
Les autres, celles comprises entre $-0,5$ et $0,5$, peuvent être considérées comme des corrélations faibles.

Le 0.95 entre cylindre et cubinches signifie que le nombre de cylindres du véhicule (cubinches) joue pour 90,25% (0,95)\*(0,95) sur la valeur du volume moteur **[Yann : ce n'est pas juste, une corrélation n'implique pas une causalité]**

```{r corrplot}
library(corrplot)
corrplot(cars.correlations,addCoef.col = "grey", number.cex = 0.5)

#' Fonction permettant d'ordonner les différentes corrélations par ordre
#' décroissant par défaut en fonction de la valeur absolue de la corrélation
#'
#' @param df le dataframe dont les corrélations sont à extraire
#' @param order paramètre optionnel pour préciser l'ordre de tri (defaut:décroi)
#' @param threshold paramètre optionnel pour préciser un seuil (défaut: <=0.5)
#' @return un tableau contenant les corrélations ordonnées
getOrderedCorrelations <- function(df, order=T, threshold=0.5) {
    orderedCor <- as.data.frame(as.table(df))
    orderedCor <- orderedCor[order(abs(orderedCor$Freq), decreasing=order),]
    orderedCor <- orderedCor[abs(orderedCor$Freq)<1 & abs(orderedCor$Freq)>=threshold,]
    rownames(orderedCor) <- NULL
    withoutDuplicated <- orderedCor[seq(from=1, to=nrow(orderedCor), by=2),]
    rownames(withoutDuplicated) <- NULL
    return(withoutDuplicated)
}

orderedCor = getOrderedCorrelations(cars.correlations)
print(orderedCor)
```

À la lecture de ce corrélogramme, on peut noter que la variable `mpg` est très fortement anti-corrélée avec les variables `cylinders`, `cubicinches`, `hp` et `weightlbs`, avec des valeurs allant de $-0,78$ à $-0,82$.
De manière générale, on remarquera de très fortes corrélations positives entre les quatre dernières variables citées (toutes supérieures à $0,85$).
Ces observations peuvent s'interpréter de la manière suivante : plus un moteur est gros, plus il est puissant et la voiture est lourde, et inversement.
Plus la voiture est grosse et puissante, et plus sa consommation en carburant sera élevée.

Des corrélations existent aussi entre ces variables et la variable `time.to.60`, bien qu'elles soient moins importantes.
On pourra noter que plus une voiture a une consommation de carburant élevée et plus elle aura une forte accélération ; plus son moteur est gros et la voiture lourde, et plus ses capacités d'accélération seront importantes.

## 5. Classification

La section qui suit est basée sur le travail disponible à [ce lien](https://rstudio-pubs-static.s3.amazonaws.com/579984_6b9efbf84ee24f00985c29e24265d2ba.html).

### 5.1 Tendance à la classification

Avant d'utiliser quelconque algorithme de classification, il peut être intéressant de quantifier la propension du jeu de données à contenir des classes distinctes et pertinentes.
Cette quantification peut être effectuée grâce au [critère d'Hopkins](https://en.wikipedia.org/wiki/Hopkins_statistic).
Ce critère permet de mettre une valeur sur le degré d'uniformisation de la distribution des valeurs d'un jeu de données.
Si la valeur prise par le critère est proche de $0$, alors les distributions sont parfaitement uniformes.
Si la valeur approche $0,5$, alors distribution des valeurs est proche de celle d'une série générée par une loi de Poisson.
Les cas qui nous intéressent sont ceux où le critère approche $1$, cette valeur indiquant des classes très clairement définies.

```{r hopkins}
library(factoextra)
get_clust_tendency(cars[-8], 100, graph=FALSE)$hopkins_stat 
```

En utilisant la fonction `get_clust_tendency` de la bibliothèque `factoextra`, on remarque que la valeur prise par le critère de Hopkins pour le jeu de données cars est très forte.
On peut donc continuer le travail de classification.

### 5.2 K-moyennes

L'algorithme des K-moyennes, très simple à mettre en place et très utilisé dans le domaine de la classification, permet de distinguer des groupes d'individus en minimisant la somme totale des carrés des distance.
Cette méthode suppose cependant de préciser en paramètre le nombre de classes du jeu de données ; cependant, dans notre cas, l'information est manquante.

Notre jeu de données étant en sept dimensions (sept variables quantitatives), il est difficile de visualiser les résultats de l'algorithme des K-moyennes pour estimer le nombre de classes le plus approprié.
Afin de surmonter ce problème, il existe de nombreuses approches mathématiques pour quantifier la qualité des résultats de l'algorithme K-moyennes.
La plus connue est celle du [coefficient de silhouette](https://fr.wikipedia.org/wiki/Silhouette_(clustering)).
Nous l'utiliserons dans un premier temps pour obtenir des résultats préliminaires.

```{r silhouette}
fviz_nbclust(cars[-8], FUNcluster = kmeans, method = c("silhouette"), k.max = 15, nboot = 100)
```

Le coefficient de silhouette mesure la qualité de la partition obtenue après avoir appliqué un algorithme de classification.
Ici, on lance une série d'algorithmes K-moyennes avec le nombre de classe minimum à $1$ et le maximum à \$15\$.
On obtient les scores moyens obtenus par les différentes partitions en fonction du nombre de classes.

On remarque que la meilleure partition a obtenu un score d'environ $0,62$ (celui-ci pouvant monter jusqu'à \$1\$) avec deux classes.
Cependant, les scores obtenus par les partitionnements à trois et quatre classes sont relativement proche du meilleur score.
La différence entre ces scores n'est pas suffisante pour en garder un seul.

Il est donc préférable de garder les partitionnements à deux, à trois, et à quatre classes comme effectué ci-dessous.
Il est à noter que, bien que ce ne soit pas précisé explicitement, $10$ itérations de l'algorithme sont effectués pour chaque partitionnement afin de pallier à l'instabilité de K-moyennes à l'initialisation.

```{r k-moyennes}
cars.cluster2 <- kmeans(cars[-8], 2) # K-moyennes pour partitionnement à deux classes,
cars.cluster3 <- kmeans(cars[-8], 3) # à trois classes,
cars.cluster4 <- kmeans(cars[-8], 4) # à quatre classes.
```

Voici maintenant une visualisation de ces partitionnement couplés aux distributions normalisées des variables :

```{r stripplots-clusters}
library(lattice)
library(gridExtra)

stripplot_clusters <- function(scaledQuantitativeValues, cluster){
    v <- as.vector(unlist(cars.scaled[-8]))
    y <- rep(c(1:ncol(scaledQuantitativeValues)), each=nrow(scaledQuantitativeValues))
    xydata <- data.frame(v, y)
    colors = rep(cluster, ncol(scaledQuantitativeValues))
    xyplot(y ~ v, 
           xydata, 
           groups=colors,
           main = paste("Distribution des variables de cars colorées par", 
                        length(unique(cluster)),
                        "classes"),
           xlab = "Distributions",
           ylab = "Index des variables de cars",
           auto.key = list(space="top", x=0, y=0),
           lattice.options = list(legend.bbox="panel"))
}
       
stripplot_clusters(cars.scaled[-8], cars.cluster2$cluster)
stripplot_clusters(cars.scaled[-8], cars.cluster3$cluster)
stripplot_clusters(cars.scaled[-8], cars.cluster4$cluster)
```

On peut voir sur ces différents graphiques les classes se séparer clairement.
On remarque que les variables corrélées voient la distributions de leurs classes être similaires, ce qui était prévisibles.
Dans la même idée, on observe que les distributions des classes sont en miroir lorsque qu'on regarde deux variables anti-corrélées.
Ces points sont tous cohérents avec les interprétations données dans la section *4.2 Corrélations*.
**[Vérifier section]**

Un point intéressant à noter est que la séparation des classes est plus prononcés pour certaines variables que pour d'autres.
Par exemple, la variable `weightlbs` (index 5) a dans les trois cas des classes parfaitement séparées.
Au contraire, `cubicinches` (index 1) voit la distribution de ses classes moins distincte.

En addition à cela, on peut comparer ces classes à la classe explicitement définie par le jeu de données : la variable `brand`.

```{r stripplots-brand}
stripplot_clusters(cars.scaled[-8], cars$brand)
```

Les voitures américaines prennent bien entendu la plus grande part des individus (voir section 4.1.2)

Faire le parallèle avec les classes

### 5.3 Classification Ascendante Hiérarchique (CAH)

Avant de commencer à travailler sur le jeu de données avec l'algorithme de la classification ascendante hiérarchique, il est important de noter que le nombre d'individus du jeu de données (261) est conséquent pour cet algorithme.
Cela signifie que le dendrogramme résultant de la CAH comportera 261 feuilles ; la visualisation sera difficilement lisible et interprétable.
Ce problème doit donc être abordé.

```{r cah, out.width="500px", fig.align='center', echo=FALSE}
library(cluster)
?agnes
cah <- agnes(cars[, -8], diss=F, metric="euclidean", stand=T, method="ward")
plot(cah)
```

*Sur le graphique des résultats changez les titres des axes x et y par `Individus` et `Seuil` et le titre du graphique par `Dendogramme`. Changez par la suite la couleur des titres par du rouge.*

```{r q1-5, out.width = "500px", fig.align='center', echo=FALSE}
plot(cah, 
     xlab="Individus", ylab="Seuil", main="Dendogramme", 
     col.axis="red", col.main="red")
```

## 6. Analyse en composantes principales

*Analysez la fonction `catdes()`. Utilisez cette fonction par rapport à la 14e variable du jeu de données `decathlon`.*

```{r q1-8-2}
library(FactoMineR)
# paramètres à ajuster
catdes(cars[, c(1:8)], 8)
```

## 7. Classification hiérarchique sur composantes principales

```{r}

```
